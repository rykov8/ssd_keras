{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.model_utils import load_weights, calc_memory_usage\n",
    "from utils.bboxes import rbox3_to_polygon, polygon_to_rbox3\n",
    "\n",
    "from tbpp_model import TBPP512, TBPP512_dense\n",
    "from ssd_data import InputGenerator\n",
    "from ssd_training import Logger\n",
    "from tbpp_training import TBPPFocalLoss\n",
    "from ssd_metric import fscore\n",
    "from sl_metric import evaluate_polygonal_results\n",
    "from ssd_viz import plot_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_synthtext import GTUtility\n",
    "with open('gt_util_synthtext_seglink.pkl', 'rb') as f:\n",
    "    gt_util = pickle.load(f)\n",
    "\n",
    "gt_util_train, gt_util_val = gt_util.split(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TextBoxes++ + DenseNet\n",
    "model = TBPP512_dense(softmax=False)\n",
    "weights_path = './checkpoints/201807091503_dsodtbpp512fl_synthtext/weights.018.h5'\n",
    "confidence_threshold = 0.35\n",
    "plot_name = 'dsodtbpp512fl_sythtext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights(model, weights_path)\n",
    "checkdir = os.path.dirname(weights_path)\n",
    "\n",
    "from tbpp_utils import PriorUtil\n",
    "prior_util = PriorUtil(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, inputs, images, data = gt_util_val.sample_random_batch(1024)\n",
    "\n",
    "preds = model.predict(inputs, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    res = prior_util.decode(preds[i], confidence_threshold, fast_nms=False)\n",
    "    bbox = res[:,0:4]\n",
    "    quad = res[:,4:12]\n",
    "    rbox = res[:,12:17]\n",
    "    #print(bbox)\n",
    "    \n",
    "    plt.figure(figsize=[8]*2)\n",
    "    plt.imshow(images[i])\n",
    "    ax = plt.gca()\n",
    "    for j in range(len(bbox)):\n",
    "        #ax.add_patch(plt.Polygon(p, fill=False, edgecolor='r', linewidth=1))\n",
    "        plot_box(bbox[j]*512, box_format='xyxy', color='b')\n",
    "        plot_box(np.reshape(quad[j],(-1,2))*512, box_format='polygon', color='r')\n",
    "        plot_box(rbox3_to_polygon(rbox[j])*512, box_format='polygon', color='g')\n",
    "        plt.plot(rbox[j,[0,2]]*512, rbox[j,[1,3]]*512, 'oc', markersize=4)\n",
    "    #prior_util.plot_gt()\n",
    "    #prior_util.plot_results(res)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(0.05, 1, 0.05)\n",
    "\n",
    "fmes_grid = np.zeros((len(steps)))\n",
    "\n",
    "for i, t in enumerate(steps):\n",
    "    results = [prior_util.decode(p, t) for p in preds]\n",
    "    TP, FP, FN = evaluate_polygonal_results([g[:,0:8] for g in data], [d[:,4:12] for d in results])\n",
    "    recall = TP / (TP+FN)\n",
    "    precision = TP / (TP+FP)\n",
    "    fmes = fscore(precision, recall)\n",
    "    fmes_grid[i] = fmes\n",
    "    print('threshold %.2f f-measure %.2f' % (t, fmes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_idx = np.argmax(fmes_grid)\n",
    "print(steps[max_idx], fmes_grid[max_idx])\n",
    "plt.figure(figsize=[12,6])\n",
    "plt.plot(steps, fmes_grid)\n",
    "plt.plot(steps[max_idx], fmes_grid[max_idx], 'or')\n",
    "plt.xticks(steps)\n",
    "plt.grid()\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('f-measure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisions, Recall, F-measue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "max_samples = gt_util_val.num_samples\n",
    "max_samples = batch_size * 32\n",
    "\n",
    "test_gt = []\n",
    "test_results = [] \n",
    "\n",
    "for i in tqdm(range(int(np.ceil(max_samples/batch_size)))):\n",
    "    inputs, data = gt_util_val.sample_batch(batch_size, i)\n",
    "    preds = model.predict(inputs, batch_size, verbose=0)\n",
    "    res = [prior_util.decode(p, confidence_threshold) for p in preds]\n",
    "    test_gt.extend(data)\n",
    "    test_results.extend(res)\n",
    "\n",
    "TP, FP, FN = evaluate_polygonal_results([g[:,0:8] for g in test_gt], [d[:,4:12] for d in test_results])\n",
    "recall = TP / (TP+FN)\n",
    "precision = TP / (TP+FP)\n",
    "fmes = fscore(precision, recall)\n",
    "\n",
    "print('samples train     %i' % (gt_util_train.num_samples))\n",
    "print('samples val       %i' % (gt_util_val.num_samples))\n",
    "\n",
    "print('samples           %i' % (max_samples))\n",
    "print('threshold         %0.3f' % (confidence_threshold))\n",
    "print('precision         %0.3f' % (precision))\n",
    "print('recall            %0.3f' % (recall))\n",
    "print('f-measure         %0.3f' % (fmes))\n",
    "\n",
    "trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "non_trainable_count = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "\n",
    "print('trainable parameters     %10i' %(trainable_count))\n",
    "print('non-trainable parameters %10i' %(non_trainable_count))\n",
    "calc_memory_usage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
